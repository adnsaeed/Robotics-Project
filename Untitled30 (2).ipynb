{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import PIL\n",
        "from base64 import b64decode, b64encode\n",
        "from google.colab import drive\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript, Image\n",
        "!pip install face_recognition\n",
        "import face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drQPSRM-4rt2",
        "outputId": "00fc44c0-fd69-4456-841d-c19a59f794cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=04aa7541abbfaa5a60cf2dc17ee3ced9f1fdbac3650ae6851fdcc559ff0c03b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-wJ53Mn4rwQ",
        "outputId": "2b70090b-ae55-4b9e-955d-24c25eaf5c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_faces(directory):\n",
        "    encodings = []\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        image = face_recognition.load_image_file(filepath)\n",
        "        face_enc = face_recognition.face_encodings(image)\n",
        "        if face_enc:\n",
        "            encodings.append(face_enc[0])\n",
        "    return encodings"
      ],
      "metadata": {
        "id": "DdN6F4i14ryf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adnan_dir = '/content/drive/MyDrive/Dataset/Adnan'\n",
        "adnan_encodings = encode_faces(adnan_dir)\n",
        "print(f\"Adnan encodings loaded: {len(adnan_encodings)}\")\n",
        "known_face_encodings = adnan_encodings\n",
        "known_face_names = [\"Adnan\"] * len(adnan_encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPo22TI34r0l",
        "outputId": "c97054c2-e30a-412e-9f31-9f4aae163ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adnan encodings loaded: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_js_image(js_reply):\n",
        "    image_data = b64decode(js_reply.split(',')[1])\n",
        "    np_img = np.frombuffer(image_data, dtype=np.uint8)\n",
        "    img = cv2.imdecode(np_img, flags=1)\n",
        "    return img"
      ],
      "metadata": {
        "id": "kQKEQsux4r2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_bbox_to_bytes(bbox_array):\n",
        "    bbox_image = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "    buffer = io.BytesIO()\n",
        "    bbox_image.save(buffer, format='png')\n",
        "    bbox_data = b64encode(buffer.getvalue()).decode('utf-8')\n",
        "    return f'data:image/png;base64,{bbox_data}'"
      ],
      "metadata": {
        "id": "KnA6iuRY5H5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_video():\n",
        "    js_code = '''\n",
        "        var video;\n",
        "        var div;\n",
        "        var stream;\n",
        "        var captureCanvas;\n",
        "        var pendingResolve;\n",
        "        var shutdown = false;\n",
        "\n",
        "        function removeElements() {\n",
        "            stream.getTracks().forEach(track => track.stop());\n",
        "            video.remove();\n",
        "            div.remove();\n",
        "        }\n",
        "\n",
        "        function onFrame() {\n",
        "            if (!shutdown) {\n",
        "                window.requestAnimationFrame(onFrame);\n",
        "            }\n",
        "            if (pendingResolve) {\n",
        "                captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "                var result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
        "                pendingResolve(result);\n",
        "                pendingResolve = null;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function createDom() {\n",
        "            if (div) return stream;\n",
        "            div = document.createElement('div');\n",
        "            document.body.appendChild(div);\n",
        "\n",
        "            video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.onclick = () => { shutdown = true; };\n",
        "            stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "            div.appendChild(video);\n",
        "\n",
        "            captureCanvas = document.createElement('canvas');\n",
        "            captureCanvas.width = 640;\n",
        "            captureCanvas.height = 480;\n",
        "            window.requestAnimationFrame(onFrame);\n",
        "\n",
        "            return stream;\n",
        "        }\n",
        "\n",
        "        async function streamFrame() {\n",
        "            if (shutdown) {\n",
        "                removeElements();\n",
        "                return '';\n",
        "            }\n",
        "            stream = await createDom();\n",
        "            return await new Promise(resolve => { pendingResolve = resolve; });\n",
        "        }\n",
        "    '''\n",
        "    display(Javascript(js_code))\n"
      ],
      "metadata": {
        "id": "kHCNLGWW5H7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_frame():\n",
        "    data = eval_js('streamFrame()')\n",
        "    return data"
      ],
      "metadata": {
        "id": "ha2hZMta5H9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smtp_server = 'smtp.office365.com'\n",
        "smtp_port = 587\n",
        "email_user = 'ProjectRobotics@hotmail.com'\n",
        "email_password = 'q1w2e3r4t5'\n",
        "email_to = 'adn20200976@std.psut.edu.jo'\n",
        "\n",
        "def send_alert_email(image):\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = email_user\n",
        "    msg['To'] = email_to\n",
        "    msg['Subject'] = 'Threat! unknown person is here!'\n",
        "\n",
        "    msg.attach(MIMEText('Threat! unknown person is here!', 'plain'))\n",
        "\n",
        "    img_data = cv2.imencode('.jpg', image)[1].tobytes()\n",
        "    image = MIMEImage(img_data, name='unknown_face.jpg')\n",
        "    msg.attach(image)\n",
        "\n",
        "    try:\n",
        "        with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
        "            server.starttls()\n",
        "            server.login(email_user, email_password)\n",
        "            server.sendmail(email_user, email_to, msg.as_string())\n",
        "            print('Email sent successfully')\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to send email: {e}\")"
      ],
      "metadata": {
        "id": "xi8P6cS16EZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "7k4I7fm14p86",
        "outputId": "148f669e-470d-4390-df73-cf85c4787dc8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        var video;\n",
              "        var div;\n",
              "        var stream;\n",
              "        var captureCanvas;\n",
              "        var pendingResolve;\n",
              "        var shutdown = false;\n",
              "\n",
              "        function removeElements() {\n",
              "            stream.getTracks().forEach(track => track.stop());\n",
              "            video.remove();\n",
              "            div.remove();\n",
              "        }\n",
              "\n",
              "        function onFrame() {\n",
              "            if (!shutdown) {\n",
              "                window.requestAnimationFrame(onFrame);\n",
              "            }\n",
              "            if (pendingResolve) {\n",
              "                captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "                var result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
              "                pendingResolve(result);\n",
              "                pendingResolve = null;\n",
              "            }\n",
              "        }\n",
              "\n",
              "        async function createDom() {\n",
              "            if (div) return stream;\n",
              "            div = document.createElement('div');\n",
              "            document.body.appendChild(div);\n",
              "\n",
              "            video = document.createElement('video');\n",
              "            video.width = 640;\n",
              "            video.onclick = () => { shutdown = true; };\n",
              "            stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            div.appendChild(video);\n",
              "\n",
              "            captureCanvas = document.createElement('canvas');\n",
              "            captureCanvas.width = 640;\n",
              "            captureCanvas.height = 480;\n",
              "            window.requestAnimationFrame(onFrame);\n",
              "\n",
              "            return stream;\n",
              "        }\n",
              "\n",
              "        async function streamFrame() {\n",
              "            if (shutdown) {\n",
              "                removeElements();\n",
              "                return '';\n",
              "            }\n",
              "            stream = await createDom();\n",
              "            return await new Promise(resolve => { pendingResolve = resolve; });\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a260f6cb783d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mjs_reply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_video_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjs_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-9ec7c160ea77>\u001b[0m in \u001b[0;36mget_video_frame\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_video_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'streamFrame()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "face_distance_threshold = 0.65\n",
        "\n",
        "stream_video()\n",
        "bbox = ''\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        js_reply = get_video_frame()\n",
        "        if not js_reply:\n",
        "            break\n",
        "\n",
        "        img = decode_js_image(js_reply)\n",
        "        bbox_array = np.zeros((480, 640, 4), dtype=np.uint8)\n",
        "\n",
        "        face_locs = face_recognition.face_locations(img)\n",
        "        face_encs = face_recognition.face_encodings(img, face_locs)\n",
        "\n",
        "        for (top, right, bottom, left), face_enc in zip(face_locs, face_encs):\n",
        "            name = \"Unknown\"\n",
        "            face_dists = face_recognition.face_distance(known_face_encodings, face_enc)\n",
        "            best_match_idx = np.argmin(face_dists)\n",
        "\n",
        "            if face_dists[best_match_idx] < face_distance_threshold:\n",
        "                name = known_face_names[best_match_idx]\n",
        "\n",
        "            cv2.rectangle(bbox_array, (left, top), (right, bottom), (255, 0, 0), 2)\n",
        "            cv2.putText(bbox_array, name, (left, bottom + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "            if name == \"Unknown\":\n",
        "                send_alert_email(img)\n",
        "\n",
        "        bbox_array[:, :, 3] = (bbox_array.max(axis=2) > 0).astype(int) * 255\n",
        "        bbox = convert_bbox_to_bytes(bbox_array)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        break"
      ]
    }
  ]
}